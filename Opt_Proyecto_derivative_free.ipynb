{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled108.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9Bs1crHARtLJswp4eLDuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairEsc/Mat_Apl/blob/main/Opt_Proyecto_derivative_free.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idea general del algoritmo.\n",
        "\n",
        "Input: \n",
        "\n",
        "\n",
        "*   $f:\\mathbb{R}^n⟶ \\mathbb{R}$, función objetivo.\n",
        "*   $x_0$, aproximación inicial.\n",
        "*   $a_{max}$, Número máximo de iteraciones para la busqueda en linea.\n",
        "*   $\\zeta$, parámetro de curvatura.\n",
        "*   $tol_g$, criterio de paro para la norma del gradiente.\n",
        "\n",
        "\n",
        "\n",
        "Descripción general del algoritmo\n",
        "\n",
        "*   Calcular $f(x_0)$\n",
        "*   Estimar $\\epsilon_f$ usando ECnoise*\n",
        "*   Calcular ** h\n",
        "*   Calcular $\\nabla_h f(x_0)$. Cuando se haga, guardar los valores $(x_s,f_s)$ que satisfacen $f_s=f(x_s)=min_{x\\in S} f(x)$, $S=\\{x+h\\cdot e_i,i=1,\\ldots,n\\}$\n",
        "*   While ($||\\nabla f(x_k)||>tol_g$):\n",
        "    *   Calcular $d_k=-H_k\\nabla_h f(x_k)$ usando L-BFGS***\n",
        "    *   Hacer line_search$(x_k,f_k,\\nabla_h f(x_k),d_k,a_{max})$ y obtiene $(x_+,f_+,\\alpha_k,LS_{flag})$\n",
        "        *   If($LS_{flag}==1$):\n",
        "            *   Invocar Recovery($x_s,f_s$)\n",
        "        *   Else:\n",
        "            *   Actualizar $x_{k+1}=x_+,$ $f_{k+1}=f_+$\n",
        "    *   Calcular $\\nabla_h f(x_{k+1})$ y guardar $(x_s,f_s)$\n",
        "    *   Calcular $s_k=x_{k+1}-x_k$, $y_k=\\nabla_h f(x_{k+1})-\\nabla_h f(x_k)$\n",
        "        *   Guardarlos si $s_k^Ty_k\\geq \\zeta||s_k||||y_k||$"
      ],
      "metadata": {
        "id": "1st1PXXNxrWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación de L-BFGS:\n",
        "Si $H_k$ es una aproximación de la inversa del Hessiano, nos interesa caluclar $d_k=-H_k\\nabla f(x_k)$.\n",
        "\n",
        "\n",
        "Input:\n",
        "\n",
        "\n",
        "\n",
        "*   $\\nabla f(x_k)$\n",
        "*   $\\{(s_{k-1},y_{k-1}),(s_{k-2},y_{k-2}),\\ldots,(s_{k-m},y_{k-m})\\}$\n",
        "*   $H^0_{k-m}$\n",
        "\n",
        "Algoritmo:\n",
        "\n",
        "\n",
        "*   Define $q=\\nabla f(x_k)$\n",
        "*   for $i=1,2,\\ldots,m$ do:\n",
        "    *   Calcular $\\alpha_i=\\rho_i s_{k-i}^Tq$\n",
        "    *   Actualiza $q=q-\\alpha_iy_i$\n",
        "*   Define $r=H^0_{k-m}q$\n",
        "*   for $i=1,2,\\ldots,m$ do:\n",
        "    *   Calcular $\\beta=\\rho_{k-i}y_{k-i}^Tr$\n",
        "    *   Actualiza $r=r-s_{k-i}(\\alpha_i-\\beta)$\n",
        "*   $r$ es una aproximación de $H_k\\nabla f(x_k)$\n"
      ],
      "metadata": {
        "id": "o9e9CVolHhpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.optimize"
      ],
      "metadata": {
        "id": "f_eEzJF9qQT8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Ioe06WYxqoi"
      },
      "outputs": [],
      "source": [
        "def L_BFGS(S,Y,g):\n",
        "    n=len(g)\n",
        "    m=len(S)\n",
        "    #supondremos H_0 un multiplo de la identidad\n",
        "    H_0=(np.dot(S[-1],Y[-1])/(np.dot(Y[-1],Y[-1])))*np.identity(n)#Dado en clase.\n",
        "    q=g\n",
        "    alphas=[]\n",
        "    for i in range(m):\n",
        "        alphas.append((1/np.dot(Y[-i],S[-i]))*np.dot(S[-i],q))\n",
        "        q=q-alphas[i]*Y[-i]\n",
        "    r=np.dot(H_0,q)\n",
        "    for i in range(m):\n",
        "        beta=(1/np.dot(Y[-i],S[-i]))*np.dot(Y[-i],r)\n",
        "        r=r+S[-i]*(alphas[i]-beta)#aproximacion de -H*g\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ECNoise(F):#F es un vector que guarda f(t_i), i=0,...,m. Evaluaciones de m+1 puntos equiespaciados\n",
        "    m=len(F)-1\n",
        "    T=np.zeros((m+1,m+1))\n",
        "    for i in range(m+1):\n",
        "        T[i,0]=F[i]\n",
        "    for k in range(m):\n",
        "        for i in range(m-k):\n",
        "            T[i,k+1]=T[i+1,k]-T[i,k]\n",
        "    return T"
      ],
      "metadata": {
        "id": "EiaLoRSdNFgA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def var_estimation(T):#Recibe la tabla.\n",
        "    m=len(T)-1\n",
        "    sigma_array=[]\n",
        "    for k in range(1,m):\n",
        "        sigma_array.append(((np.math.factorial(k)/np.math.factorial(2*k))/(m+1-k))*np.sum(T.T[k]**2))\n",
        "    #Ahora checamos las 2 condiciones.\n",
        "    for k in range(1,m-2):\n",
        "        max_k=np.max(sigma_array[k:k+2])\n",
        "        min_k=np.min(sigma_array[k:k+2])\n",
        "        if(max_k<=4*min_k):\n",
        "            if(np.sign(min_k*max_k)==-1):\n",
        "                print(\"es el \", k)\n",
        "                break\n",
        "    return np.sqrt(sigma_array[k])#Podria ser que las condiciones no se cumplan, en tal caso regresa la ultima estimacion sigma."
      ],
      "metadata": {
        "id": "gQcG9CUNagT4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aprox_f_biprima(e_f,f,x_k,p):#Usando una direccion (aleatoria dada) se aproxima el max ||Hessiana_f(x_k)*p||\n",
        "    tao_1=100\n",
        "    tao_2=0.1\n",
        "    h_a=e_f**(1/4)\n",
        "    f_mas=f(x_k+h_a*p)\n",
        "    f_menos=f(x_k-h_a*p)\n",
        "    f_0=f(x_k)\n",
        "    delta_h_a=abs(f_mas+f_menos-2*f_0)\n",
        "    mu_a=delta_h_a/(h_a**2)\n",
        "    if(delta_h_a/e_f>=tao_1 and abs(f_mas-f_0)<=tao_2*np.max(f_mas,f_menos,f_0) and abs(f_menos-f_0)<=tao_2*np.max(f_mas,f_menos,f_0)):\n",
        "        return mu_a\n",
        "    h_b=(e_f/mu_a)**(1/4)\n",
        "    f_mas=f(x_k+h_b*p)\n",
        "    f_menos=f(x_k-h_b*p)\n",
        "    delta_h_b=abs(f_mas+f_menos-2*f_0)\n",
        "    mu_b=delta_h_b/(h_b**2)\n",
        "    if(delta_h_b/e_f>=tao_1 and abs(f_mas-f_0)<=tao_2*np.max(f_mas,f_menos,f_0) and abs(f_menos-f_0)<=tao_2*np.max(f_mas,f_menos,f_0)):\n",
        "        return mu_b\n",
        "    if(abs(mu_a-mu_b)<=0.5*mu_b):\n",
        "        return mu_b\n",
        "    return mu_a\n"
      ],
      "metadata": {
        "id": "Y9wkwLTs-3Sh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_f(f,x_k,h):#Regresa el gradiente, y los valores minimos (x_s,f_s)\n",
        "    n=len(x_k)\n",
        "    g=np.zeros(n)\n",
        "    f_k=f(x_k)\n",
        "    for i in range(n):\n",
        "        p=np.eye(1,n,i)\n",
        "        if(i==0):\n",
        "            f_s_1=f(x_k+h*p)\n",
        "            x_s=x_k+h*p\n",
        "        f_s_2=f(x_k+h*p)\n",
        "        g[i]=(f_s_2-f_k)/h\n",
        "        if(f_s_2<f_s_1):\n",
        "            f_s_1=f_s_2\n",
        "            x_s=x_k+h*p\n",
        "    print \n",
        "    return (g,[x_s,f_s_1])"
      ],
      "metadata": {
        "id": "8qAw2SGTLoXa",
        "outputId": "711cacc2-5348-4f74-827a-8aeb46d052ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 0.53608598, -0.42068635, -0.99068159, -0.64984875]), [array([[1.  , 2.  , 3.01, 4.  ]]), 1.1251791084758342])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usare sccipy.optimize.line_search() para la busqueda en linea."
      ],
      "metadata": {
        "id": "hRI_tI2IR9Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test-------------------\n",
        "def f(t):\n",
        "    return (np.cos(t)+np.sin(t)+10**(-3)*np.random.uniform(0,2*np.sqrt(3)))\n",
        "f_vec=np.vectorize(f)\n",
        "h=10**(-2)\n",
        "F=f_vec([i*h for i in range(7)])\n",
        "Tabla=(ECNoise(F))\n",
        "for line in Tabla:\n",
        "    print(' '.join(map(str, line)))\n",
        "print(var_estimation(Tabla))\n",
        "e_f=var_estimation()\n",
        "mu=aprox_f_biprima()\n",
        "h=(8**(1/4))*(e_f/mu)**(1/2)\n",
        "#Ya podemos calcular la defivada direccional.\n",
        "#---------------------------"
      ],
      "metadata": {
        "id": "zh0S_ywoa-zP",
        "outputId": "322d9f58-6007-4a74-c803-df1558ab1b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0034110608985265 0.009062448331822903 0.00045583912561575346 0.000686839208466905 -0.0042561994632051015 0.013298924894368902 -0.03339660584348603\n",
            "1.0124735092303494 0.009518287457438657 0.0011426783340826585 -0.0035693602547381964 0.0090427254311638 -0.020097680949117125 0.0\n",
            "1.021991796687788 0.010660965791521315 -0.002426681920655538 0.005473365176425604 -0.011054955517953324 0.0 0.0\n",
            "1.0326527624793094 0.008234283870865777 0.0030466832557700663 -0.00558159034152772 0.0 0.0 0.0\n",
            "1.0408870463501751 0.011280967126635844 -0.002534907085757654 0.0 0.0 0.0 0.0\n",
            "1.052168013476811 0.00874606004087819 0.0 0.0 0.0 0.0 0.0\n",
            "1.0609140735176892 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "0.0002099216400467252\n"
          ]
        }
      ]
    }
  ]
}